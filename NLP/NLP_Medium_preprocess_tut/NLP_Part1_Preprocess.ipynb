{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Part1-Preprocess",
      "provenance": [],
      "authorship_tag": "ABX9TyNEpsdVY/7EVUL3kyKz2nf2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mraniketr/DeepLearningProjects/blob/master/NLP_Part1_Preprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGkNULhJ_9L9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c95d024b-f6b6-48d0-ee0a-001e8c0185a5"
      },
      "source": [
        "import nltk                               \n",
        "from nltk.corpus import twitter_samples    \n",
        "import matplotlib.pyplot as plt            \n",
        "import random                             \n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')\n",
        "import re                                  \n",
        "import string                              \n",
        "\n",
        "from nltk.corpus import stopwords          \n",
        "from nltk.stem import PorterStemmer       \n",
        "from nltk.tokenize import TweetTokenizer"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJaNVI5WEu0Y",
        "colab_type": "text"
      },
      "source": [
        "Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K-XCjmJAlOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_tweets= twitter_samples.strings('positive_tweets.json')\n",
        "negative_tweets= twitter_samples.strings('negative_tweets.json')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsop9-BmBTwc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a7e95dda-4fc4-4622-b566-dab62da14667"
      },
      "source": [
        "tweet= positive_tweets[48]\n",
        "tweet"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our new product line is in our #etsy shop now! Check it out :) http://t.co/h8exCTLQxg #boxroomcrafts'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFe4nqyLCk9D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c7e641d-6a3e-4a7e-b35b-74b24466bfca"
      },
      "source": [
        "#remove RT\n",
        "tweet_n = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "# remove hyperlinks\n",
        "tweet_n = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet_n)\n",
        "\n",
        "# remove hashtags\n",
        "tweet_n = re.sub(r'#', '', tweet_n)\n",
        "\n",
        "print(tweet_n)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our new product line is in our etsy shop now! Check it out :) \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xGU6nobvExBp",
        "colab_type": "text"
      },
      "source": [
        "Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M94MmyOnEwhs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "15472220-a2bc-4912-f154-b06a3d0d5163"
      },
      "source": [
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "\n",
        "tokens = tokenizer.tokenize(tweet_n)\n",
        "\n",
        "print(tokens)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['our', 'new', 'product', 'line', 'is', 'in', 'our', 'etsy', 'shop', 'now', '!', 'check', 'it', 'out', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZgHxzBHGVRp",
        "colab_type": "text"
      },
      "source": [
        "Remove stop words and punctuations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dguqcBoIGWJY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d8f1769-9fb2-4c99-8584-f03996a13dc0"
      },
      "source": [
        "tweets_clean = []\n",
        "stopwords_english = stopwords.words('english') \n",
        "\n",
        "for word in tokens:\n",
        "    if (word not in stopwords_english and  word not in string.punctuation):  \n",
        "        tweets_clean.append(word)\n",
        "print(tweets_clean)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['new', 'product', 'line', 'etsy', 'shop', 'check', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGrZ2RDFSnZ5",
        "colab_type": "text"
      },
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br6mEGOCSFlm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83cfbd17-f34c-42f4-8494-b45f4ef8792c"
      },
      "source": [
        "stemmer = PorterStemmer() \n",
        "\n",
        "tweets_stem = [] \n",
        "\n",
        "for word in tweets_clean:\n",
        "    stem_word = stemmer.stem(word) \n",
        "    tweets_stem.append(stem_word)  \n",
        "\n",
        "print(tweets_stem)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['new', 'product', 'line', 'etsi', 'shop', 'check', ':)']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}